{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4aa7498",
   "metadata": {},
   "source": [
    "# Promi Exercise Sheet 2: Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7146882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:56:18.535599Z",
     "start_time": "2024-12-03T18:56:18.530926Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math "
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "41c23ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:56:20.853472Z",
     "start_time": "2024-12-03T18:56:20.849803Z"
    }
   },
   "source": [
    "def test_true(test_name, value: bool):\n",
    "    if value:\n",
    "        #print(\"\\033[92mTest {}: passed.\\033[0m\".format(test_name))\n",
    "        print(f'Test {test_name}: passed.')\n",
    "    else:\n",
    "        #print(\"\\033[91mTest {}: failed.\\033[0m\".format(test_name))\n",
    "        print(f'Test {test_name}: failed.')\n",
    "\n",
    "# equality\n",
    "def test_almost_equal(test_name, value: float, target: float, precision: float = 1e-4):\n",
    "    test_true(test_name, abs(value - target) < precision)\n",
    "\n",
    "# almost equal\n",
    "def test_almost_zero(test_name, value: float, precision: float = 1e-4):\n",
    "    test_almost_equal(test_name, value, 0.0, precision=precision)\n",
    "\n",
    "def test_almost_equal_array(test_name, value: np.ndarray, target: np.ndarray, precision: float = 1e-4):\n",
    "    test_true(test_name, np.all(np.abs(value - target) < precision))\n",
    "\n",
    "def test_shape_equal(test_name, arr, des_shape):\n",
    "    test_true(test_name, arr.shape==des_shape)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "a6a572c6",
   "metadata": {},
   "source": [
    "# Part 1: Modeling Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce059d-8154-4529-a550-3b2947a232f1",
   "metadata": {},
   "source": [
    "## Question 1.1: Implement PMF/PDF of distributions\n",
    "In this task  implement the Probability Mass function/Probability Density function of the following distributions.\n",
    "1. Bernoulli\n",
    "2. Binomial\n",
    "3. Poisson\n",
    "4. Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "id": "b61da042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:56:25.320378Z",
     "start_time": "2024-12-03T18:56:25.318335Z"
    }
   },
   "source": [
    "def bernoulli(k:int,p:float):\n",
    "    return (1 - p) if k == 0 else p"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "35a7973d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:56:26.770615Z",
     "start_time": "2024-12-03T18:56:26.768520Z"
    }
   },
   "source": [
    "def binomial(k:int,n:int,p:int):\n",
    "    return math.comb(n, k) * (p ** k) * ((1 - p) ** (n - k))"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "8b183050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T18:59:39.726187Z",
     "start_time": "2024-12-03T18:59:39.724515Z"
    }
   },
   "source": [
    "def poisson(k:int,lam:float):\n",
    "    return ((lam ** k) / (math.factorial(k))) * (math.e ** (- lam))"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "0f13017f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T19:08:26.358759Z",
     "start_time": "2024-12-03T19:08:26.353987Z"
    }
   },
   "source": [
    "def gaussian(x:float,mu:float,sigma:float):\n",
    "    return (1 / math.sqrt(2 * math.pi * sigma ** 2)) * math.exp(-(x - mu) ** 2 / (2 * sigma ** 2))"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "9016f463",
   "metadata": {},
   "source": [
    "#### Public Tests"
   ]
  },
  {
   "cell_type": "code",
   "id": "62375c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T19:09:51.051348Z",
     "start_time": "2024-12-03T19:09:51.047752Z"
    }
   },
   "source": [
    "test_cases_bernoulli = [((0,0.5), 0.5), ((1,0.5), 0.5), ((0,0.2), 0.8), ((1,0.2), 0.2)]\n",
    "\n",
    "for i,((k,p), sol) in enumerate(test_cases_bernoulli):\n",
    "    test_almost_equal(f\"bernoulli {i}\", bernoulli(k,p), sol)\n",
    "print(\"\\n\")\n",
    "\n",
    "test_cases_binomial = [((5,2,0.5), 0.3125), ((5,3,0.5), 0.3125), ((5,2,0.2), 0.2048), ((5,3,0.2), 0.0512)]\n",
    "\n",
    "for i,((n,k,p), sol) in enumerate(test_cases_binomial):\n",
    "    test_almost_equal(f\"binomial {i}\", binomial(k,n,p), sol)\n",
    "print(\"\\n\")\n",
    "\n",
    "test_cases_poisson = [((0,1), 0.3678), ((1,1), 0.3678), ((0,2), 0.13534), ((1,2), 0.27067)]\n",
    "for i,((k,lam), sol) in enumerate(test_cases_poisson):\n",
    "    test_almost_equal(f\"poisson {i}\", poisson(k,lam), sol)\n",
    "print(\"\\n\")\n",
    "\n",
    "test_cases_gaussian = [((0,0,1), 0.3989), ((1,0,1), 0.24197), ((600,897,200), 0.00066225), ((8,10,35), 0.01138)]\n",
    "for i,((x,mu,sigma), sol) in enumerate(test_cases_gaussian):\n",
    "    test_almost_equal(f\"gaussian {i}\", gaussian(x,mu,sigma), sol)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test bernoulli 0: passed.\n",
      "Test bernoulli 1: passed.\n",
      "Test bernoulli 2: passed.\n",
      "Test bernoulli 3: passed.\n",
      "\n",
      "\n",
      "Test binomial 0: passed.\n",
      "Test binomial 1: passed.\n",
      "Test binomial 2: passed.\n",
      "Test binomial 3: passed.\n",
      "\n",
      "\n",
      "Test poisson 0: passed.\n",
      "Test poisson 1: passed.\n",
      "Test poisson 2: passed.\n",
      "Test poisson 3: passed.\n",
      "\n",
      "\n",
      "Test gaussian 0: passed.\n",
      "Test gaussian 1: passed.\n",
      "Test gaussian 2: passed.\n",
      "Test gaussian 3: passed.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "a41305da-e6c7-49f8-9af6-0526ca4a5c4e",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "Using the implemented PMFs/PDFs, create a plot for each distribution that visualizes the PMF/PDF in a range specified below. Furthermore, visualize the mean and standard deviation of the distributions. Furthermore, explain the parameters of the distributions beneath the plot.\n",
    "\n",
    "Note: In the following tasks you will be asked to visualize at least 2 pdfs/pmfs per distribution with different parameters. Please only use one plot to visualize both pdfs/pmfs.\n",
    "Note: Think about a smart way to visualize the mean and the standard deviation so that the plot is easy to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdfd7b",
   "metadata": {},
   "source": [
    "### 1. Bernoulli Distribution: Create 2 pmfs of the Bernoulli distributions with follwing parameters\n",
    "- $p=0.2$\n",
    "- $p= 0.653$\n",
    "    \n",
    "**Hint**: Use the plt.bar() function from matplotlib to visualize the distributions.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_bernolli():\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "plt_bernolli()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b49db4",
   "metadata": {},
   "source": [
    "Explain here the parameters of the Bernoulli distribution\n",
    "\n",
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479bda9d",
   "metadata": {},
   "source": [
    "### 2. Binomial Distribution: Plot the pmf for 2 different Binomial distributions\n",
    "     \n",
    "- $n=50$, $p=0.2$\n",
    "- $n=50$, $p=0.6$\n",
    "\n",
    "**Hint**: Use the `plt.scatter()` function to plot the distributions.\n",
    "\n",
    "**Hint**: One possible range of visualization is $k \\in [0,50]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_binomial():\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "plt_binomial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff74ff",
   "metadata": {},
   "source": [
    "Explain here the parameters of the Binomial distribution\n",
    "\n",
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ca37e",
   "metadata": {},
   "source": [
    "### 3. Poisson Distribution: Plot 2 poisson distributions with the following parameters.\n",
    "\n",
    "- $\\lambda = 1$\n",
    "- $\\lambda = 10$\n",
    "\n",
    "**Hint**: Use the plt.scatter() function from matplotlib to visualize the distribution.\n",
    "\n",
    "**Hint**: One possible range of visualisation is $k \\in [0,20]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a48026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_poisson():\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "\n",
    "plt_poisson()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d66191",
   "metadata": {},
   "source": [
    "Here explain the parameters of the Poisson distribution\n",
    "\n",
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350dde2",
   "metadata": {},
   "source": [
    "4. Gaussian Distribution: Plot 2 Gaussian Distribution with the following parameters:\n",
    "    - $\\mu=0$ $\\sigma= 5$\n",
    "    - $\\mu = 46$ $\\sigma=10$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_gaussian():\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "\n",
    "plt_gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ddf2d",
   "metadata": {},
   "source": [
    "Explain here the parameters of the Gaussian distribution\n",
    "\n",
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f067b6-65a4-46a0-acb2-312bc7677471",
   "metadata": {},
   "source": [
    "## Question 1.3.\n",
    "Explain the relationship between Bernoulli and binomial, binomial and Poisson, binomial and Gaussian.\n",
    "\n",
    "### 1. Bernoulli and bionmial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776fa3ad",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5994e",
   "metadata": {},
   "source": [
    "### 2. Binomial and Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f50d0",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e7e11",
   "metadata": {},
   "source": [
    "### 3. Binomial and Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb2feb",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83416302-e454-49f3-8162-93f125f20e7b",
   "metadata": {},
   "source": [
    "## Question 2.1: Transformations\n",
    "Suppose $X$ is a continuous random variable with pdf $f_X$ and cdf $F_X$.\n",
    "Let $Z = |X|$. First, show that the cdf $F_Z$ of $Z$ is given by $F_Z(z) = F_X(z) - F_X(-z)$. Then, show that the pdf $f_Z$ of $Z$ is given by $f_Z(z) = f_X(z) + f_X(-z)$.\n",
    "\n",
    "**Hint**: Think about how you can use properties $Z=|X|$ to solve this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252ea28-be8c-4cd1-9d43-619dcea7bd86",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a0efe-83e0-4fbc-bd04-adf2ccf1c215",
   "metadata": {},
   "source": [
    "## Question 2.2: Change of variable\n",
    "Let $Y = a + bX$ with $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R} \\setminus 0$. Show that the pdf $p_Y$ of $Y$ is given by $p_Y(y) = \\frac{1}{|b|}p_X(\\frac{y-a}{b}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4acdb-d1a2-4934-9234-3440247c7145",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cf9a62-5068-4f03-b36c-9bd85646a91e",
   "metadata": {},
   "source": [
    "## Question 3.1: Categorical Distribution\n",
    "We can represent a categorical distribution using an array e.g. `p = np.array([0.1, 0.2, 0.7])`.\n",
    "Write a function `plot_categorical(p: np.ndarray)` that creates a plot of the distribution given a probability array `p`.\n",
    "\n",
    "**Note**: Implement the function so that the number of categories can be chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical(p: np.ndarray):\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "p = np.array([0.1, 0.2, 0.7])\n",
    "plot_categorical(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874a89b-7641-4aa7-81c2-315d24b3fa35",
   "metadata": {},
   "source": [
    "## Question 3.2: Convolution\n",
    "Write a convolution function that given two categorical distributions computes their convolution. Implement the convolution computation on your own and **do not** use already implemented functions from libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_convolution(p1:np.ndarray, p2:np.ndarray):\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa28eea",
   "metadata": {},
   "source": [
    "### PUBLIC TESTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [((np.array([0.2, 0.8]), np.array([0.3, 0.7])), np.array([0.06, 0.38, 0.56])),((np.array([0.1, 0.9]), np.array([0.2, 0.5,0.3])), np.array([0.02, 0.23, 0.48,0.27]))]\n",
    "for i,((p1, p2), sol) in enumerate(test_cases):\n",
    "    test_almost_equal_array(f\"convolution {i}\", compute_convolution(p1, p2), sol)\n",
    "    test_almost_equal(f\"Sum convolution {i}\",np.sum(compute_convolution(p1,p2)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bcfa3",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "If your convolution is implemented correctly. We can now use the `plot_categorical` function to visualize the convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e23c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.array([0.5, 0.0, 0.5])\n",
    "p2 = np.array([0.3, 0.4, 0.05,0.05,0.2])\n",
    "\n",
    "result = compute_convolution(p1, p2)\n",
    "plot_categorical(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf185a-a214-475c-86f0-3eaeccfd9708",
   "metadata": {},
   "source": [
    "## Question 3.3.1\n",
    "Implement the function `convolve_n_times(p:np.ndarray,n:int)` that computes the convolution of $N$ independent and identically distributed categorical random variables. Use the functions `compute_convolution` from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92324581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_n_times(p: np.ndarray,n:int):\n",
    "    #### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6220b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PUBLIC TESTS\n",
    "test_cases = [((np.array([0.2, 0.8]), 3), np.array([0.0016, 0.0256, 0.1536, 0.4096, 0.4096])),((np.array([0.1, 0.9]), 10), np.array([1.00000000e-11, 9.90000000e-10, 4.45500000e-08, 1.20285000e-06,2.16513000e-05, 2.72806380e-04 ,2.45525742e-03, 1.57837977e-02\n",
    " ,7.10270897e-02,2.13081269e-01, 3.83546284e-01, 3.13810596e-01]))]\n",
    "\n",
    "for i,((p1, n), sol) in enumerate(test_cases):\n",
    "    test_almost_equal_array(f\"convolution {i}\", convolve_n_times(p1, n), sol)\n",
    "    test_almost_equal(f\"Sum convolution {i}\",np.sum(convolve_n_times(p1,n)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37ff0e",
   "metadata": {},
   "source": [
    "## Question 3.3.2\n",
    "Now we plot the convolution for $N=1$, $N=10$, $N=100$, $N=1000$. What do you notice?\n",
    "\n",
    "**Hint**: Think about the Central Limited Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a98ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([0.1, 0.2, 0.7])\n",
    "result_1 = convolve_n_times(p, 1)\n",
    "result_10 = convolve_n_times(p, 10)\n",
    "result_100 = convolve_n_times(p, 100)\n",
    "result_1000 = convolve_n_times(p, 1000)\n",
    "\n",
    "plot_categorical(result_1)\n",
    "plot_categorical(result_10)\n",
    "plot_categorical(result_100)\n",
    "plot_categorical(result_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca3b3b",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde6059",
   "metadata": {},
   "source": [
    "## Question 4: Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd36c4a",
   "metadata": {},
   "source": [
    "### Q4.1: Mean and Variance of Gaussian Mixture Models\n",
    "Derive the mean and variance of a Gaussian Mixture Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a3e86",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a098f",
   "metadata": {},
   "source": [
    "### Q4.2: Mixture Model Class\n",
    "Implement the following functions to complete the `GaussianMixtureModel` class.\n",
    "\n",
    "a) PMF: Implement the pmf of the mixture of Gaussians in `pdf`.\n",
    "\n",
    "b) Sampling:\n",
    "Implement a function that draws a sample from a Gaussian Mixture Model. Sampling consists of two steps:\n",
    "First, sample which mixture component should be used.\n",
    "Second, sample from the corresponding Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureModel:\n",
    "\n",
    "    def __init__(self, pi, mus, sigmas, seed=0) -> None:\n",
    "        self.n = len(mus)\n",
    "        self.pi = pi\n",
    "        self.mus = mus\n",
    "        self.sigmas = sigmas\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def pdf(self, x):\n",
    "        #### YOUR SOLUTION HERE\n",
    "\n",
    "    def sample(self, n_samples: int):\n",
    "        #### YOUR SOLUTION HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF test\n",
    "import scipy\n",
    "test_cases = [\n",
    "    (([0.3, 0.7], [1, 0], [1, 4], 42, 2), 0.13420),\n",
    "    (([1], [0], [0.1], 42, 0), 3.98942),\n",
    "    (([1], [0], [0.1], 42, 1), 0),\n",
    "    (([0.2, 0.5, 0.3], [1, 0, 5], [1, 4, 0.2], 42, 5), 0.62127),\n",
    "    (([0.2, 0.3, 0.4, 0.1], [1, 0, 5, 2], [2, 4, 0.2, 1], 42, 1), 0.09309),\n",
    "]\n",
    "for i, ((pi, mu, sigma, seed, x), sol) in enumerate(test_cases):\n",
    "    # Compute DGL step using your function\n",
    "    model = GaussianMixtureModel(\n",
    "        pi=pi,\n",
    "        mus=mu,\n",
    "        sigmas=sigma,\n",
    "        seed=seed\n",
    "    )\n",
    "    pred = model.pdf(x)\n",
    "    test_almost_equal(f'{i}', pred, sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a297c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling test\n",
    "test_cases = [\n",
    "    (\n",
    "        ([0.3, 0.7], [1, 0], [1, 4], 42, 10),\n",
    "        ([-1.87789754,  2.17024017, -1.85367077, -1.86291901,  1.24196227, -0.91328024, -0.72491783, -2.24915012, -4.05132448,  1.25698933])\n",
    "    )\n",
    "]\n",
    "\n",
    "for i, ((pi, mu, sigma, seed, n_samples), sol) in enumerate(test_cases):\n",
    "    # Compute DGL step using your function\n",
    "    model = GaussianMixtureModel(\n",
    "        pi=pi,\n",
    "        mus=mu,\n",
    "        sigmas=sigma,\n",
    "        seed=seed\n",
    "    )\n",
    "    pred = model.sample(n_samples)\n",
    "    test_shape_equal(f'{i} [shape]', pred, (n_samples,))\n",
    "    test_almost_equal_array(f'{i} [vals]', pred, sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab8618",
   "metadata": {},
   "source": [
    "## Question 5: Non-Parametric Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69075fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianMixtureModel(\n",
    "    pi=[0.2, 0.25, 0.4, 0.15],\n",
    "    mus=[-1, 0, 3, 9],\n",
    "    sigmas=[1, 4, 2, 0.5],\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d269f8",
   "metadata": {},
   "source": [
    "### Q5.1: Sampling\n",
    "Sample a dataset of points using the mixture model defined above. \n",
    "In a single plot, plot:\n",
    "\n",
    "1. The distribution of points in a histogram.\n",
    "2. The corresponding ground-truth distribution (mixture of Gaussians)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b0850",
   "metadata": {},
   "source": [
    "### Q5.2: Kernels\n",
    "Implement the following kernels:\n",
    "1. Uniform\n",
    "2. Epanechnikow\n",
    "3. Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_kernel(x):\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "def epanechnikov_kernel(x):\n",
    "    #### YOUR SOLUTION HERE\n",
    "\n",
    "def gaussian_kernel(x):\n",
    "    #### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2108ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel test\n",
    "test_cases = [\n",
    "    (1, (0.5, 0, 0.24197)),\n",
    "    (2, (0., 0, 0.05)),\n",
    "    (0.1, (0.5, 0.7425, 0.39695)),\n",
    "]\n",
    "\n",
    "for i, (x, (s1, s2, s3)) in enumerate(test_cases):\n",
    "    # Compute DGL step using your function\n",
    "    p1 = uniform_kernel(x)\n",
    "    p2 = epanechnikov_kernel(x)\n",
    "    p3 = gaussian_kernel(x)\n",
    "    # print(pred)\n",
    "    test_almost_equal(f'{i} [uniform]', p1, s1)\n",
    "    test_almost_equal(f'{i} [epanechnikov]', p2, s2)\n",
    "    test_almost_equal(f'{i} [gaussian]', p3, s3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97b9c3",
   "metadata": {},
   "source": [
    "### Q5.3: Kernel Density Estimation\n",
    "Given points and a kernel, compute the kernel density estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kde(x, kernel_fct, pts, h):\n",
    "    #### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab084268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE Test \n",
    "\n",
    "test_cases = [\n",
    "    ((1, np.linspace(-10, 10, 100), 0.1), (0.05, 0.01302, 0.04875)),\n",
    "    ((2, np.linspace(-10, 10, 100), 0.8), (0.05, 0.04984, 0.0495)),\n",
    "]\n",
    "\n",
    "for i, ((x, pts, h), (s1, s2, s3)) in enumerate(test_cases):\n",
    "    # Compute DGL step using your function\n",
    "    p1 = compute_kde(x, uniform_kernel, pts, h)\n",
    "    p2 = compute_kde(x, epanechnikov_kernel, pts, h)\n",
    "    p3 = compute_kde(x, gaussian_kernel, pts, h)\n",
    "    test_almost_equal(f'{i} [uniform]', p1, s1)\n",
    "    test_almost_equal(f'{i} [epanechnikov]', p2, s2)\n",
    "    test_almost_equal(f'{i} [gaussian]', p3, s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b63fe",
   "metadata": {},
   "source": [
    "### Q5.4: Plot the kernel density estimation alongside the ground-truth distribution\n",
    "Create a single plot, containing the following:\n",
    "1. The ground truth Gaussian mixture distribution from 5.1\n",
    "2. The sampled points in a histogram\n",
    "3. The uniform KDE for $h=0.05$, $0.2$, $1$\n",
    "4. The Epanechnikov KDE for $h=0.05$, $0.2$, $1$\n",
    "5. The Gaussian KDE for $h=0.05$, $0.2$, $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba742cdf29760c12",
   "metadata": {},
   "source": [
    "# Part 2: Parametric Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fbb56e7567fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T17:23:53.745711Z",
     "start_time": "2024-11-26T17:23:53.743609Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "from scipy.stats import beta as beta_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fbb043f5c6ab3",
   "metadata": {},
   "source": [
    "## Question 1: MLE for Categorical Distributions\n",
    "Let's consider an experiment with $K$ different outcomes. The outcomes are modeled as a one-hot encoding\n",
    "        $$\\boldsymbol{x}\\in\\{0, 1\\}^K; \\qquad \\sum_{i=1}^{K} x_i = 1$$\n",
    "\n",
    "We chose to model the outcome of the experiment by a random variable $X$ which is distributed as categorical distribution with probability-mass function (pmf) $f(\\boldsymbol{x};\\boldsymbol{\\theta}) = \\prod_{i=1}^{K}\\theta_i^{x_i}$ where $\\theta_i$ represents the probability of $x_i$. Thus, we need to make sure that $\\sum_{i = 1}^K \\theta_i = 1$.\n",
    "        \n",
    "Assume now that we are given a set of data $\\mathcal{D} = \\{\\boldsymbol{x}_j|j=1,\\dots,N\\}$. Please derive the parameters of the categorical distribution $\\theta_i^{\\mathrm{ml}}$ that maximize the pmf given the data $\\mathcal{D}$.\n",
    "\n",
    "_Hint 1_: If you do it right, the (not explicitly mentioned) constraint $\\forall i: \\theta_i \\in [0, 1]$ is always fulfilled by the optimal solution. So you can safely ignore it in your derivations.\\\n",
    "_Hint 2_: Rewrite the constraint $\\sum_{i=1}^{K} \\theta_i = 1$ as $\\theta_K = 1 - \\sum_{i=1}^{K-1} \\theta_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7bb4b3fcad2eaf",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be9540a81525af",
   "metadata": {},
   "source": [
    "## Question 2: Modelling a Die\n",
    "We now consider an experiment where we throw a die. \n",
    "Which distribution would you choose to model the outcome that we throw a 6. Please state the parameters of your chosen distribution and derive the maximum likelihood parameters. How is your chosen distribution connected to the Categorical distribution?\n",
    "\n",
    "Hint: You don't need to do all calculations again to obtain the maximum likelihood parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef77418f1d4457",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99462d9f78e9a39b",
   "metadata": {},
   "source": [
    "## Question 3: Modelling N Dice\n",
    "Next up, we consider throws with $m$ dice. To determine how many 6s we can throw with $m$ dice, we model the experiment by a binomial distribution. \n",
    "The random variable $X$ can take values in $x\\in\\{1,\\dots, n\\}$ modeling how many times we threw a 6 with $m$ dice. \n",
    "The pmf for the binomial is\n",
    "        \n",
    "$$f_n(x;\\theta) = \\begin{pmatrix}\n",
    "            n\\\\x\n",
    "  \\end{pmatrix} \\theta^{x} (1-\\theta)^{n-x}.$$\n",
    "        \n",
    "Here $m$ denotes the number of dice, $x$ denotes the number of times that a 6 has been thrown, and $\\theta$ is the probability of throwing a 6.\n",
    "  \n",
    "The maximum likelihood estimate of the binomial distribution given a dataset $\\mathcal{D}$ can be shown to be\n",
    "        \n",
    "$$\\theta^{\\mathrm{ml}} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{x_i}{m}.$$\n",
    "        \n",
    "Please plot the data, which you can collect for $m=10$ throws using the below code, against the binomial distribution with the maximum likelihood estimate $\\theta^{\\mathrm{ml}}$ for the $N=10, 100, 1000$ first data points in the dataset. Describe the differences between the three plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e8ed444036d23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T17:23:53.758011Z",
     "start_time": "2024-11-26T17:23:53.755501Z"
    }
   },
   "outputs": [],
   "source": [
    "M = 10\n",
    "P = 1 / 6\n",
    "\n",
    "\n",
    "def draw_binomial(n: int):\n",
    "    rng = np.random.default_rng(42)\n",
    "    return rng.binomial(M, P, size=n)\n",
    "\n",
    "\n",
    "DATA = draw_binomial(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eab7dadcbf0e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T17:23:54.069379Z",
     "start_time": "2024-11-26T17:23:53.804590Z"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6183a6aac29f1ca",
   "metadata": {},
   "source": [
    "We can see that the data matches better with higher number of data points, i.e. if more evidence is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3c3efc86bbe11",
   "metadata": {},
   "source": [
    "## Question 4: Parameter Priors\n",
    "The beta distribution is a continuous univariate distribution over $\\theta$, parameterized by $\\alpha$ and $\\beta$ with pdf\n",
    "        \n",
    "\\begin{align*}\n",
    "    \\mathrm{beta}(\\theta;\\alpha, \\beta) &= \\frac{1}{\\mathrm{B}(\\alpha, \\beta)} \\theta^{\\alpha - 1}(1-\\theta)^{\\beta - 1}; \\quad \\theta\\in(0,1)\\\\\n",
    "    \\mathrm{B}(\\alpha, \\beta) &= \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha +  \\beta)}\n",
    "\\end{align*}\n",
    "        \n",
    "Here $\\mathrm{B}(\\alpha, \\beta)$ is the beta-function, represented by the gamma-function, which acts as a normalization constant. \n",
    "The term is not required for further calculations and thus, we will not further introduce it.\n",
    "\n",
    "Let's assume that the parameters $\\theta$ of the binomial distribution $\\mathrm{binomial}_n(x|\\theta)$ introduced in Question 3 are random variables. \n",
    "We define the prior over the parameters by a beta distribution with $\\alpha_0$, $\\beta_0$. \n",
    "Calculate the posterior of the likelihood under the beta prior. Which type of distribution does the posterior assume? \n",
    "How is this concept called in the literature?\n",
    "\n",
    "Hint: Please elaborate if you need to explicitly calculate the evidence. \n",
    "Use the fact that the posterior is proportional to the joint distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e411de946549d2",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850999b4b05dc9b3",
   "metadata": {},
   "source": [
    "## Question 5: Posterior Updates\n",
    "In Bayesian inference, the posterior is updated sequentially by adding more and more data. Please plot the prior distribution, with $\\alpha_0 = \\beta_0 = 1$, and the posterior distribution $p(\\theta|x_{1:N})$ for the first $N=1,2,5,10,100$ datapoints. \n",
    "Use the results of the previous question. \n",
    "Also, plot the maximum likelihood estimate of the binomial distribution for $N=1000$ datapoints from Question 3. \n",
    "Interpret the results and outline the differences between Bayesian estimation and maximum likelihood estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e6061907d6f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T17:23:54.361998Z",
     "start_time": "2024-11-26T17:23:54.075897Z"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbea234039b62c",
   "metadata": {},
   "source": [
    "#### YOUR SOLUTION HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
